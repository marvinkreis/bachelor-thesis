\chapter{Conclusion}
\label{cha:conclusion}

In this work, we took on the issue of automated assessment of Scratch programs.
There exist multiple previous approaches that tackled this problem.
We examined Hairball~\cite{hairball}, which analyzes Scratch programs by performing static analysis on them,
as well as ITCH~\cite{itch}, which transforms Scratch programs to automate \texttt{ask} and \texttt{say} blocks.
We described various challenges, that have to be overcome in order to perform automated testing for Scratch.
These challenges include Scratch's code system, which runs parallel scripts, its IO, which is not trivial to automate for testing,
as well as some common traits in Scratch programs, which can make automated testing difficult.
\parspace

As the main contribution of this work, we introduced Whisker, a utility that automates Scratch 3.0's IO,
and described a way to perform runtime testing on Scratch programs by using this automation.
Whisker allows tests to control the execution of Scratch programs,
to programmatically simulate user input on them,
and to obtain information about the sprites and variables of the program.
It also offers additional features like measuring statement coverage of Scratch programs
and automated test input generation.
\parspace

We introduced a testing procedure that checks properties by defining constraints that the program under test must hold.
Whisker checks these constraints in the background while the program is executed.
This provides more flexibility about the execution of the program under test,
making it possible to test with various sources of simulated user inputs, for example with randomly generated input.
For this purpose, we implemented an automated input generation algorithm in Whisker,
which detects what inputs the program can react to through static analysis, and randomly performs these inputs on the program.
\parspace

We evaluated Whisker in three separate experiments.
In the first experiment, we ran multiple test suites on a set of student-written Scratch programs.
We learned that our testing approach is able to consistently produce test results that closely match the results of manual assessment.
In the second experiment we tested the automated input algorithm by measuring its achieved statement coverage
on a set of different programs.
We observed that it is able to cover most of usual Scratch programs' code,
and produces much higher coverage compared to running the program without any simulated inputs.
Finally, we investigated if the additional computations done by Whisker and the test code would interfere with the program under test
by slowing it down, and discovered that this is not the case.
\parspace

In conclusion, we proved automating Scratch's IO to be a viable way to perform functional testing on Scratch programs.
We were able to achieve accurate test results both by alternatingly running the program and performing assertions, and by checking constraints in the background while the program is running.
Therefore, we believe that automated testing may aid in the assessment of Scratch assignments in the future,
both for grading purposes and for students or independent learners to check their own solutions.
